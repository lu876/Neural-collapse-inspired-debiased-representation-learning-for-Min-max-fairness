{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4409643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm, trange\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    \"\"\"\n",
    "    Changes the seed for reproducibility. \n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(2048)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "path = r\"adult.json\"\n",
    "test_path = r\"adult_test.json\"\n",
    "train_df = pd.read_json(path)\n",
    "test_df = pd.read_json(test_path)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d327f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def get_naive_dataset(dataset):\n",
    "    X = dataset.drop(['income'], axis=1)\n",
    "    y = dataset['income']\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 2**28 )# 2**(0))\n",
    "    a_train = x_train['sex']\n",
    "    a_test = x_test['sex']\n",
    "    x_train = x_train.drop(['race','sex'], axis=1)\n",
    "    x_test = x_test.drop(['race','sex'], axis=1)\n",
    "    return (x_train, y_train, a_train), (x_test, y_test, a_test)\n",
    "\n",
    "(x_train, y_train, a_train), (x_valid, y_valid, a_valid) = get_naive_dataset(train_df)\n",
    "x_test, y_test, a_test = test_df.drop(['income','race','sex'], axis=1), test_df['income'], test_df['sex']\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "def make_dataloader(data, y, a,batch_size):\n",
    "    dataset = BasicDataset(data, y, a)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "class BasicDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, target, sensitive):\n",
    "        super().__init__()\n",
    "        self.data = torch.tensor(data.values)\n",
    "        self.target = torch.tensor(target.values)\n",
    "        self.sensitive = torch.tensor(sensitive.values)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data.float()[idx], self.target[idx], self.sensitive[idx]\n",
    "    \n",
    "training_loader = make_dataloader(x_train, y_train, a_train, batch_size)\n",
    "valid_loader = make_dataloader(x_valid, y_valid, a_valid, batch_size)\n",
    "test_loader = make_dataloader(x_test, y_test, a_test, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tablur_Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Tablur_Model, self).__init__()\n",
    "        nodes = 32\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(32, nodes)\n",
    "        self.fc2 = nn.Linear(nodes, 2*nodes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87848b08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "def test(net, classifier, dataloader, print_fairness=True):\n",
    "    net.eval()\n",
    "    test_pred = []\n",
    "    test_gt = []\n",
    "    sense_gt = []\n",
    "    female_predic = []\n",
    "    female_gt = []\n",
    "    male_predic = []\n",
    "    male_gt = []\n",
    "    correct_00, total_00 = 0, 0\n",
    "    correct_01, total_01 = 0, 0\n",
    "    correct_10, total_10 = 0, 0\n",
    "    correct_11, total_11 = 0, 0\n",
    "    classifier = classifier.to(device)\n",
    "    with torch.no_grad():\n",
    "        with tqdm(dataloader, unit=\"batch\") as tepoch:\n",
    "            for content in tepoch:\n",
    "                test, label, sensitive = content\n",
    "                test = test.to(device)\n",
    "                \n",
    "                mask_00 = ((label == 0) & (sensitive == 0))\n",
    "                mask_01 = ((label == 0) & (sensitive == 1))\n",
    "                mask_10 = ((label == 1) & (sensitive == 0))\n",
    "                mask_11 = ((label == 1) & (sensitive == 1))\n",
    "            \n",
    "            \n",
    "                test_feature = net(test)\n",
    "                prediction = classifier(test_feature)\n",
    "                \n",
    "                \n",
    "                _, predic = torch.max(prediction.data, 1)\n",
    "                predic = predic.detach().cpu()\n",
    "                test_pred.extend(predic.numpy())\n",
    "                test_gt.extend(label)\n",
    "                sense_gt.extend(sensitive)\n",
    "                correct_00 += (predic[mask_00] == label[mask_00]).float().sum().item()\n",
    "                total_00 += mask_00.float().sum().item()\n",
    "\n",
    "                correct_01 += (predic[mask_01] == label[mask_01]).float().sum().item()\n",
    "                total_01 += mask_01.float().sum().item()\n",
    "\n",
    "                correct_10 += (predic[mask_10] == label[mask_10]).float().sum().item()\n",
    "                total_10 += mask_10.float().sum().item()\n",
    "\n",
    "                correct_11 += (predic[mask_11] == label[mask_11]).float().sum().item()\n",
    "                total_11 += mask_11.float().sum().item() \n",
    "                \n",
    "        acc_00 = correct_00 / total_00\n",
    "        acc_01 = correct_01 / total_01\n",
    "        acc_10 = correct_10 / total_10\n",
    "        acc_11 = correct_11 / total_11\n",
    "\n",
    "        print(f'Accuracy for y=0, s=0: {acc_00}', total_00)\n",
    "        print(f'Accuracy for y=0, s=1: {acc_01}', total_01)\n",
    "        print(f'Accuracy for y=1, s=0: {acc_10}', total_10)\n",
    "        print(f'Accuracy for y=1, s=1: {acc_11}', total_11)     \n",
    "\n",
    "\n",
    "        for i in range(len(sense_gt)):\n",
    "            if sense_gt[i] == 0:\n",
    "                female_predic.append(test_pred[i])\n",
    "                female_gt.append(test_gt[i])\n",
    "            else:\n",
    "                male_predic.append(test_pred[i])\n",
    "                male_gt.append(test_gt[i])\n",
    "\n",
    "        female_CM = confusion_matrix(female_gt, female_predic)    \n",
    "        male_CM = confusion_matrix(male_gt, male_predic) \n",
    "        female_dp = (female_CM[1][1]+female_CM[0][1])/(female_CM[0][0]+female_CM[0][1]+female_CM[1][0]+female_CM[1][1])\n",
    "        male_dp = (male_CM[1][1]+male_CM[0][1])/(male_CM[0][0]+male_CM[0][1]+male_CM[1][0]+male_CM[1][1])\n",
    "        female_TPR = female_CM[1][1]/(female_CM[1][1]+female_CM[1][0])\n",
    "        male_TPR = male_CM[1][1]/(male_CM[1][1]+male_CM[1][0])\n",
    "        female_FPR = female_CM[0][1]/(female_CM[0][1]+female_CM[0][0])\n",
    "        male_FPR = male_CM[0][1]/(male_CM[0][1]+male_CM[0][0])\n",
    "        if print_fairness == True:\n",
    "            EOd = 0.5*(abs(female_FPR-male_FPR)+abs(female_TPR-male_TPR))\n",
    "            print('Female TPR', female_TPR)\n",
    "            print('male TPR', male_TPR)\n",
    "            print('DP',abs(female_dp - male_dp))\n",
    "            print('EOP', abs(female_TPR - male_TPR))\n",
    "            print('EoD', EOd)\n",
    "            print('acc', accuracy_score(test_gt, test_pred))\n",
    "        else:\n",
    "            EOd = 0.5*(abs(female_FPR-male_FPR)+abs(female_TPR-male_TPR))\n",
    "        return accuracy_score(test_gt, test_pred), EOd\n",
    "\n",
    "\n",
    "def train_model():\n",
    "    model = Tablur_Model()\n",
    "    model = model.to(device)\n",
    "    epoch = 100\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    mean_criterion = nn.MSELoss()\n",
    "    acc = 0\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "    train_loss = []\n",
    "    valid_loss =[]\n",
    "    \n",
    "    classifier = nn.Linear(2*32, 2)\n",
    "        \n",
    "    for epoches in range(epoch):\n",
    "        with tqdm(training_loader, unit=\"batch\") as tepoch:\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            feature_y_0_a0 = []\n",
    "            feature_y_0_a1 = []\n",
    "            feature_y_1_a0 = []\n",
    "            feature_y_1_a1 = []\n",
    "            loss00 = 0\n",
    "            loss01 = 0\n",
    "            loss10 = 0\n",
    "            loss11 = 0\n",
    "            \n",
    "            with torch.no_grad(): \n",
    "                for step, (valid_input, valid_target, validsensitive) in enumerate(valid_loader):\n",
    "                    valid_input = valid_input.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        valid_feature = model(valid_input)\n",
    "                        label = valid_target.squeeze().detach().cpu()\n",
    "                        mask_00 = ((label == 0) & (validsensitive == 0))\n",
    "                        mask_01 = ((label == 0) & (validsensitive == 1))\n",
    "                        mask_10 = ((label == 1) & (validsensitive == 0))\n",
    "                        mask_11 = ((label == 1) & (validsensitive == 1))\n",
    "                        g1 = valid_feature[mask_00]\n",
    "                        g2 = valid_feature[mask_01]\n",
    "                        g3 = valid_feature[mask_10]\n",
    "                        g4 = valid_feature[mask_11]\n",
    "                        feature_y_0_a0.extend(g1.detach().cpu().numpy())\n",
    "                        feature_y_0_a1.extend(g2.detach().cpu().numpy())\n",
    "                        feature_y_1_a0.extend(g3.detach().cpu().numpy())\n",
    "                        feature_y_1_a1.extend(g4.detach().cpu().numpy())\n",
    "\n",
    "                feature_g2 = np.array(feature_y_0_a1)\n",
    "                feature_g4 = np.array(feature_y_1_a1)\n",
    "                feature_g2_tensor = torch.from_numpy(feature_g2)\n",
    "                feature_g4_tensor = torch.from_numpy(feature_g4)\n",
    "\n",
    "                mu_1 = torch.mean(feature_g2_tensor, 0)\n",
    "                mu_1 = mu_1 /torch.norm(mu_1)\n",
    "                mu_2 = torch.mean(feature_g4_tensor, 0)\n",
    "                mu_2 = mu_2 /torch.norm(mu_2)\n",
    "                weight = torch.cat((mu_1.unsqueeze(0), mu_2.unsqueeze(0)), 0)\n",
    "                print(\"sim:\",  F.cosine_similarity(mu_1.unsqueeze(0), mu_2.unsqueeze(0)) )\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    classifier.weight = nn.Parameter(weight)\n",
    "            \n",
    "            \n",
    "            \n",
    "            for train_input, train_target, sensitive in tepoch:\n",
    "                train_input = train_input.to(device)\n",
    "                label = train_target.detach().cpu() \n",
    "                one_hot_labels = F.one_hot(train_target, num_classes=2)\n",
    "                train_target = one_hot_labels.float().to(device)\n",
    "                \n",
    "                feature = model(train_input)\n",
    "                classifier = classifier.to(device)\n",
    "                outputs  = classifier(feature)\n",
    "            \n",
    "                mask_00 = ((label== 0) & (sensitive == 0))\n",
    "                mask_01 = ((label == 0) & (sensitive == 1))\n",
    "                mask_10 = ((label == 1) & (sensitive == 0))\n",
    "                mask_11 = ((label == 1) & (sensitive == 1))\n",
    "                \n",
    "                count_00 = mask_00.sum()\n",
    "                count_01 = mask_01.sum()\n",
    "                count_10 = mask_10.sum()\n",
    "                count_11 = mask_11.sum()\n",
    "                \n",
    "                if count_01==0 or count_10==0 or count_00 == 0 or count_11 == 0:\n",
    "                    continue\n",
    "                g1_f = feature[mask_00]\n",
    "                g2_f = feature[mask_01]\n",
    "                \n",
    "                mu1 = torch.mean(g1_f, 0)\n",
    "                mu2 = torch.mean(g2_f, 0)\n",
    "                    \n",
    "                g3_f = feature[mask_10]\n",
    "                g4_f = feature[mask_11]\n",
    "                \n",
    "                mu3 = torch.mean(g3_f, 0)\n",
    "                mu4 = torch.mean(g4_f, 0)\n",
    "                \n",
    "                loss_mean = mean_criterion(mu3, mu4) + mean_criterion(mu1, mu2)\n",
    "                \n",
    "                \n",
    "                if count_00 > 0:\n",
    "                    loss_00 = criterion(outputs[mask_00], train_target[mask_00])\n",
    "                    loss00 += loss_00.item()\n",
    "                else:\n",
    "                    loss_00 = torch.tensor(0)\n",
    "                if count_01 > 0:\n",
    "                    loss_01 = criterion(outputs[mask_01], train_target[mask_01])\n",
    "                    loss01 += loss_01.item()\n",
    "                else:\n",
    "                    loss_01 = torch.tensor(0)\n",
    "                if count_10 > 0:\n",
    "                    loss_10 = criterion(outputs[mask_10], train_target[mask_10])\n",
    "                    loss10 += loss_10.item()\n",
    "                else:\n",
    "                    loss_10 = torch.tensor(0)\n",
    "                if count_11 > 0:\n",
    "                    loss_11 = criterion(outputs[mask_11], train_target[mask_11])\n",
    "                    loss11 += loss_11.item()\n",
    "                else:\n",
    "                    loss_11 = torch.tensor(0)\n",
    "\n",
    "                loss = loss_00 + loss_01 + loss_10 + loss_11 + loss_mean\n",
    "                \n",
    "                \n",
    "                tepoch.set_postfix(ut_loss = loss.item())\n",
    "\n",
    "                optimizer.zero_grad()    \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                tepoch.set_description(f\"epoch %2f \" % epoches)\n",
    "        print('Testing')        \n",
    "        _,  _ = test(model,classifier, test_loader, True)\n",
    "        \n",
    "\n",
    "train_model()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLcourse]",
   "language": "python",
   "name": "conda-env-DLcourse-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
